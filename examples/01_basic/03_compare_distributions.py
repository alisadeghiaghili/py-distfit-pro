"""\nComparing Multiple Distributions\n=================================\n\nSystematic approach to finding the best distribution\nfor your data by comparing multiple candidates.\n\nUse Case:\n---------\nYou don't know which distribution fits your data best.\nCompare multiple families and select winner using AIC/BIC.\n\nAuthor: Ali Sadeghi Aghili\n\"\"\"\n\nimport numpy as np\nfrom distfit_pro import DistFitter\nfrom distfit_pro.core.comparison import compare_distributions\n\nprint(\"â•" * 70)\nprint(\"ðŸ“Š COMPARING MULTIPLE DISTRIBUTIONS\")\nprint(\"â•" * 70)\n\n\n# ============================================================================\n# EXAMPLE 1: Basic Comparison with DistFitter\n# ============================================================================\n\nprint(\"\\n" + \"â”€" * 70)\nprint(\"Example 1: Automatic Distribution Selection\\n\")\n\n# E-commerce: daily sales amounts ($)\nnp.random.seed(123)\nsales = np.random.lognormal(mean=7, sigma=0.8, size=365)\n\nprint(f\"Data: {len(sales)} days of sales\")\nprint(f\"Mean: ${sales.mean():.2f}\")\nprint(f\"Median: ${np.median(sales):.2f}\")\nprint(f\"Std: ${sales.std():.2f}\\n\")\n\n# Compare common distributions\nfitter = DistFitter(distributions=[\n    'normal',\n    'lognormal', \n    'gamma',\n    'exponential',\n    'weibull'\n])\n\nfitter.fit(sales)\n\nprint(\"Comparison Results:\")\nprint(fitter.summary())\n\nprint(\"\\nðŸ† Winner:\")\nbest = fitter.get_best_distribution()\nprint(f\"  {best.info.display_name}\")\nprint(f\"  Parameters: {best.params}\")\nprint(f\"  AIC: {best.aic():.2f}\")\n\n\n# ============================================================================\n# EXAMPLE 2: Detailed Comparison with Ranking\n# ============================================================================\n\nprint(\"\\n" + \"â•" * 70)\nprint(\"Example 2: Ranked Comparison with Statistics\\n\")\n\n# Manufacturing: defect rates per batch\ndefect_rates = np.random.beta(a=2, b=20, size=200) * 100  # percentage\n\nprint(f\"\\nData: {len(defect_rates)} batches\")\nprint(f\"Mean defect rate: {defect_rates.mean():.2f}%\")\nprint(f\"Range: {defect_rates.min():.2f}% - {defect_rates.max():.2f}%\\n\")\n\n# Compare distributions\ncandidates = ['normal', 'gamma', 'beta', 'weibull', 'lognormal']\nresults = compare_distributions(defect_rates, candidates)\n\nprint(\"ðŸ“Š Ranking (by AIC):\\n\")\nfor i, (name, metrics) in enumerate(results.items(), 1):\n    print(f\"{i}. {name:15s} AIC={metrics['aic']:8.2f}  BIC={metrics['bic']:8.2f}  LL={metrics['log_likelihood']:8.2f}\")\n\nbest_name = list(results.keys())[0]\nprint(f\"\\nâœ“ Best fit: {best_name}\")\n\n\n# ============================================================================\n# EXAMPLE 3: Using Different Metrics\n# ============================================================================\n\nprint(\"\\n" + \"â•" * 70)\nprint(\"Example 3: Comparison Using BIC (Bayesian IC)\\n\")\n\n# Server response times (ms)\nresponse_times = np.random.gamma(shape=2, scale=50, size=1000)\n\nprint(f\"\\nData: {len(response_times)} API calls\")\nprint(f\"Mean response: {response_times.mean():.1f}ms\")\nprint(f\"95th percentile: {np.percentile(response_times, 95):.1f}ms\\n\")\n\n# BIC penalizes complexity more than AIC\n# Good for larger datasets\nfitter = DistFitter(\n    distributions=['normal', 'gamma', 'exponential', 'weibull'],\n    metric='bic'  # Use BIC instead of AIC\n)\n\nfitter.fit(response_times)\n\nprint(\"Results (ranked by BIC):\")\nprint(fitter.summary())\n\n\n# ============================================================================\n# EXAMPLE 4: Family-Specific Comparison\n# ============================================================================\n\nprint(\"\\n" + \"â•" * 70)\nprint(\"Example 4: Comparing Within Distribution Family\\n\")\n\n# Financial returns (symmetric, possibly heavy-tailed)\nreturns = np.random.standard_t(df=5, size=500) * 0.02  # 2% volatility\n\nprint(f\"\\nData: {len(returns)} daily returns\")\nprint(f\"Mean: {returns.mean()*100:.3f}%\")\nprint(f\"Std: {returns.std()*100:.2f}%\\n\")\n\n# Compare symmetric distributions\n# (Normal vs t-distribution for heavy tails)\nfitter = DistFitter(distributions=['normal', 't', 'laplace'])\nfitter.fit(returns)\n\nprint(\"Comparison of Symmetric Distributions:\")\nprint(fitter.summary())\n\nbest = fitter.get_best_distribution()\nprint(f\"\\nðŸ’¡ Insight: {best.info.display_name} captures tail behavior better\")\n\n\n# ============================================================================\n# EXAMPLE 5: Visual Comparison\n# ============================================================================\n\ntry:\n    import matplotlib.pyplot as plt\n    \n    print(\"\\n" + \"â•" * 70)\n    print(\"Example 5: Visual Comparison of Top Candidates\\n\")\n    \n    # Website load times (ms)\n    load_times = np.random.lognormal(mean=5, sigma=0.6, size=800)\n    \n    print(f\"Data: {len(load_times)} page loads\")\n    print(f\"Median: {np.median(load_times):.0f}ms\\n\")\n    \n    # Fit and plot top 3\n    fitter = DistFitter()\n    fitter.fit(load_times)\n    \n    fig = fitter.plot(top_n=3)\n    plt.suptitle('Website Load Time Distribution Comparison', \n                 fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    \n    print(\"âœ“ Created comparison plot (top 3 distributions)\")\n    print(\"  Close window to continue...\")\n    plt.show()\n    \nexcept ImportError:\n    print(\"\\nâš ï¸  matplotlib not available - skipping visualization\")\n\n\n# ============================================================================\n# EXAMPLE 6: Practical Decision Making\n# ============================================================================\n\nprint(\"\\n" + \"â•" * 70)\nprint(\"Example 6: Using Comparison for Real Decisions\\n\")\n\n# Customer lifetime value (CLV)\nclv_data = np.random.pareto(a=2.5, size=500) * 1000 + 500\n\nprint(f\"\\nData: {len(clv_data)} customers\")\nprint(f\"Mean CLV: ${clv_data.mean():.2f}\")\nprint(f\"Median CLV: ${np.median(clv_data):.2f}\\n\")\n\n# Compare candidates\nfitter = DistFitter(distributions=[\n    'normal',\n    'lognormal',\n    'gamma',\n    'pareto'  # Good for power-law data\n])\n\nfitter.fit(clv_data)\nprint(fitter.summary())\n\nbest = fitter.get_best_distribution()\n\n# Use best distribution for business planning\nprint(\"\\nðŸ’¼ Business Insights:\")\n\n# Top 10% customers\ntop_10_threshold = best.ppf(0.90)\nprint(f\"â€¢ Top 10% customer threshold: ${top_10_threshold:.2f}\")\n\n# Expected revenue from 1000 new customers\nexpected_total = best.mean() * 1000\nprint(f\"â€¢ Expected total from 1000 customers: ${expected_total:,.2f}\")\n\n# 95% confidence interval for single customer\nci_low = best.ppf(0.025)\nci_high = best.ppf(0.975)\nprint(f\"â€¢ 95% CI for single customer: ${ci_low:.2f} - ${ci_high:.2f}\")\n\n\n# ============================================================================\n# KEY TAKEAWAYS\n# ============================================================================\n\nprint(\"\\n" + \"â•" * 70)\nprint(\"ðŸŽ“ KEY TAKEAWAYS\")\nprint(\"â•" * 70)\nprint(\"\"\"\n1. TWO WAYS TO COMPARE:\n   a) DistFitter class (automatic, user-friendly)\n      - fitter = DistFitter(distributions=[...])\n      - fitter.fit(data)\n      - fitter.summary() shows ranking\n   \n   b) compare_distributions() function (programmatic)\n      - results = compare_distributions(data, candidates)\n      - Returns dict with metrics for each distribution\n\n2. SELECTION METRICS:\n   - AIC (Akaike): General purpose, balances fit vs complexity\n   - BIC (Bayesian): Penalizes complexity more (prefer for large data)\n   - Log-Likelihood: Raw fit quality (ignore complexity)\n   - Use AIC by default, BIC for n > 1000\n\n3. CANDIDATE SELECTION:\n   - Start with domain knowledge (physics, business logic)\n   - Common starting sets:\n     * Positive data: [lognormal, gamma, weibull, exponential]\n     * Symmetric: [normal, t, laplace]\n     * Bounded: [beta, uniform]\n     * Counts: [poisson, negative_binomial]\n\n4. INTERPRETATION:\n   - Small Î”AI C < 2: Models essentially equivalent\n   - Î”AIC 2-10: Winner clearly better\n   - Î”AIC > 10: Winner much better\n\n5. NEXT STEPS:\n   - See 05_goodness_of_fit.py for validation tests\n   - See examples/03_plotting/ for beautiful comparisons\n   - See examples/02_advanced/01_weighted_fitting.py for survey data\n\"\"\")\