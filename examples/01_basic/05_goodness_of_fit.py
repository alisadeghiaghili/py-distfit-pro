"""\nGoodness of Fit Testing\n========================\n\nValidate that your chosen distribution actually fits the data well.\nUse statistical tests and visual diagnostics.\n\nUse Case:\n---------\nYou've selected a distribution. Before using it for decisions,\nverify it's a good fit using hypothesis tests and diagnostics.\n\nAuthor: Ali Sadeghi Aghili\n\"\"\"\n\nimport numpy as np\nfrom scipy import stats\nfrom distfit_pro import get_distribution, DistFitter\n\nprint(\"‚ïê" * 70)\nprint(\"‚úÖ GOODNESS OF FIT TESTING\")\nprint(\"‚ïê" * 70)\n\n\n# ============================================================================\n# EXAMPLE 1: AIC/BIC Comparison\n# ============================================================================\n\nprint(\"\\n" + \"‚îÄ" * 70)\nprint(\"Example 1: AIC/BIC Model Selection\\n\")\n\n# Revenue data (right-skewed)\nnp.random.seed(42)\nrevenue = np.random.lognormal(mean=10, sigma=0.8, size=500)\n\nprint(f\"Data: {len(revenue)} observations\")\nprint(f\"Mean: ${revenue.mean():.2f}\\n\")\n\n# Fit candidates\ncandidates = ['normal', 'lognormal', 'gamma']\nresults = {}\n\nfor name in candidates:\n    dist = get_distribution(name)\n    dist.fit(revenue)\n    \n    results[name] = {\n        'aic': dist.aic(),\n        'bic': dist.bic(),\n        'll': dist.log_likelihood()\n    }\n\nprint(\"Model Comparison:\\n\")\nprint(f\"{'Distribution':<15} {'AIC':>10} {'BIC':>10} {'Log-Lik':>10}\")\nprint(\"‚îÄ" * 50)\n\nfor name, metrics in sorted(results.items(), key=lambda x: x[1]['aic']):\n    print(f\"{name:<15} {metrics['aic']:>10.2f} {metrics['bic']:>10.2f} {metrics['ll']:>10.2f}\")\n\nbest = min(results.items(), key=lambda x: x[1]['aic'])[0]\nprint(f\"\\n‚úì Best by AIC: {best}\")\n\n# Interpretation\naic_diff = results['normal']['aic'] - results[best]['aic']\nif aic_diff < 2:\n    print(\"  ‚Üí Models essentially equivalent\")\nelif aic_diff < 10:\n    print(f\"  ‚Üí {best} clearly better (ŒîAIC = {aic_diff:.1f})\")\nelse:\n    print(f\"  ‚Üí {best} much better (ŒîAIC = {aic_diff:.1f})\")\n\n\n# ============================================================================\n# EXAMPLE 2: Kolmogorov-Smirnov Test\n# ============================================================================\n\nprint(\"\\n" + \"‚ïê" * 70)\nprint(\"Example 2: Kolmogorov-Smirnov Test\\n\")\n\n# Test data (truly normal)\ndata_normal = np.random.normal(50, 10, 300)\n\n# Fit normal\ndist_normal = get_distribution('normal')\ndist_normal.fit(data_normal)\n\n# KS test\nks_stat, ks_pval = stats.kstest(\n    data_normal,\n    lambda x: dist_normal.cdf(x)\n)\n\nprint(f\"Normal distribution fit to normal data:\")\nprint(f\"  KS statistic: {ks_stat:.4f}\")\nprint(f\"  p-value:      {ks_pval:.4f}\\n\")\n\nif ks_pval > 0.05:\n    print(\"‚úì Cannot reject H‚ÇÄ: Data consistent with fitted distribution\")\n    print(\"  (Good fit!)\")\nelse:\n    print(\"‚úó Reject H‚ÇÄ: Data inconsistent with fitted distribution\")\n    print(\"  (Poor fit - try another distribution)\")\n\n# Try fitting wrong distribution\nprint(\"\\nTrying exponential on same data (should fail):\")\ndist_exp = get_distribution('exponential')\n# Exponential needs positive data\ndata_positive = data_normal - data_normal.min() + 1\ndist_exp.fit(data_positive)\n\nks_stat2, ks_pval2 = stats.kstest(\n    data_positive,\n    lambda x: dist_exp.cdf(x)\n)\n\nprint(f\"  KS statistic: {ks_stat2:.4f}\")\nprint(f\"  p-value:      {ks_pval2:.4f}\\n\")\n\nif ks_pval2 < 0.05:\n    print(\"‚úó Poor fit detected! (as expected)\")\n\n\n# ============================================================================\n# EXAMPLE 3: Chi-Square Goodness of Fit\n# ============================================================================\n\nprint(\"\\n" + \"‚ïê" * 70)\nprint(\"Example 3: Chi-Square Test (Binned Data)\\n\")\n\n# Count data (Poisson)\ncounts = np.random.poisson(lam=5, size=400)\n\nprint(f\"Data: {len(counts)} observations\")\nprint(f\"Mean count: {counts.mean():.2f}\\n\")\n\n# Fit Poisson\nfrom distfit_pro.distributions.discrete import PoissonDistribution\ndist_poisson = PoissonDistribution()\ndist_poisson.fit(counts)\n\nprint(f\"Fitted Œª: {dist_poisson.params['lam']:.3f}\\n\")\n\n# Chi-square test\n# Bin the data\nbins = np.arange(0, counts.max() + 2)\nobs_freq, _ = np.histogram(counts, bins=bins)\n\n# Expected frequencies\nexp_freq = []\nfor i in range(len(bins) - 1):\n    p_bin = dist_poisson.cdf(bins[i+1]) - dist_poisson.cdf(bins[i])\n    exp_freq.append(p_bin * len(counts))\n\nexp_freq = np.array(exp_freq)\n\n# Combine bins with < 5 expected\nmask = exp_freq >= 5\nobs_combined = obs_freq[mask]\nexp_combined = exp_freq[mask]\n\n# Chi-square statistic\nchi2_stat = np.sum((obs_combined - exp_combined)**2 / exp_combined)\ndf = len(obs_combined) - 1 - 1  # bins - 1 - num_params\nchi2_pval = 1 - stats.chi2.cdf(chi2_stat, df)\n\nprint(f\"Chi-square test:\")\nprint(f\"  œá¬≤ statistic: {chi2_stat:.3f}\")\nprint(f\"  df:           {df}\")\nprint(f\"  p-value:      {chi2_pval:.4f}\\n\")\n\nif chi2_pval > 0.05:\n    print(\"‚úì Good fit (cannot reject H‚ÇÄ)\")\nelse:\n    print(\"‚úó Poor fit (reject H‚ÇÄ)\")\n\n\n# ============================================================================\n# EXAMPLE 4: Q-Q Plot Analysis\n# ============================================================================\n\ntry:\n    import matplotlib.pyplot as plt\n    \n    print(\"\\n" + \"‚ïê" * 70)\n    print(\"Example 4: Q-Q Plot Visual Diagnostic\\n\")\n    \n    # Good fit example\n    data_gamma = np.random.gamma(3, 2, 500)\n    dist_gamma = get_distribution('gamma')\n    dist_gamma.fit(data_gamma)\n    \n    # Create Q-Q plot\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n    \n    # Q-Q plot\n    sorted_data = np.sort(data_gamma)\n    n = len(sorted_data)\n    theoretical_quantiles = dist_gamma.ppf(np.linspace(0.01, 0.99, n))\n    \n    ax1.scatter(theoretical_quantiles, sorted_data, alpha=0.5, s=20)\n    ax1.plot([sorted_data.min(), sorted_data.max()], \n             [sorted_data.min(), sorted_data.max()], \n             'r--', lw=2, label='Perfect fit')\n    ax1.set_xlabel('Theoretical Quantiles')\n    ax1.set_ylabel('Sample Quantiles')\n    ax1.set_title('Q-Q Plot: Gamma Distribution')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Histogram with PDF overlay\n    ax2.hist(data_gamma, bins=30, density=True, alpha=0.6, label='Data')\n    x_range = np.linspace(data_gamma.min(), data_gamma.max(), 200)\n    ax2.plot(x_range, dist_gamma.pdf(x_range), 'r-', lw=2, label='Fitted PDF')\n    ax2.set_xlabel('Value')\n    ax2.set_ylabel('Density')\n    ax2.set_title('Histogram vs Fitted Distribution')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    print(\"‚úì Q-Q plot created\")\n    print(\"  ‚Ä¢ Points near red line ‚Üí Good fit\")\n    print(\"  ‚Ä¢ Systematic deviation ‚Üí Poor fit\")\n    print(\"  Close window to continue...\")\n    plt.show()\n    \nexcept ImportError:\n    print(\"\\n‚ö†Ô∏è  matplotlib not available - skipping Q-Q plot\")\n\n\n# ============================================================================\n# EXAMPLE 5: Residual Analysis\n# ============================================================================\n\nprint(\"\\n" + \"‚ïê" * 70)\nprint(\"Example 5: Residual Analysis\\n\")\n\n# Fit data\ndata = np.random.weibull(2, 400) * 10\ndist = get_distribution('weibull')\ndist.fit(data)\n\n# Calculate residuals (probability integral transform)\n# Should be uniform [0, 1] if good fit\npit_values = dist.cdf(data)\n\nprint(f\"PIT (Probability Integral Transform) Analysis:\\n\")\n\n# Test uniformity with KS test\nks_stat, ks_pval = stats.kstest(pit_values, 'uniform')\nprint(f\"  KS test for uniformity:\")\nprint(f\"    Statistic: {ks_stat:.4f}\")\nprint(f\"    p-value:   {ks_pval:.4f}\\n\")\n\nif ks_pval > 0.05:\n    print(\"‚úì PIT values are uniform ‚Üí Good fit\")\nelse:\n    print(\"‚úó PIT values not uniform ‚Üí Poor fit\")\n\n# Check for patterns\nprint(f\"\\n  PIT summary statistics:\")\nprint(f\"    Mean:     {pit_values.mean():.3f}  (should be ‚âà0.5)\")\nprint(f\"    Std:      {pit_values.std():.3f}  (should be ‚âà0.289)\")\nprint(f\"    Skewness: {stats.skew(pit_values):.3f}  (should be ‚âà0)\")\n\n\n# ============================================================================\n# EXAMPLE 6: Practical Decision Framework\n# ============================================================================\n\nprint(\"\\n" + \"‚ïê" * 70)\nprint(\"Example 6: Complete Validation Workflow\\n\")\n\ndef validate_fit(data, dist, alpha=0.05):\n    \"\"\"\n    Complete validation of distribution fit.\n    Returns dict with multiple test results.\n    \"\"\"\n    results = {}\n    \n    # 1. AIC/BIC\n    results['aic'] = dist.aic()\n    results['bic'] = dist.bic()\n    \n    # 2. KS test\n    ks_stat, ks_pval = stats.kstest(data, lambda x: dist.cdf(x))\n    results['ks_pval'] = ks_pval\n    results['ks_pass'] = ks_pval > alpha\n    \n    # 3. PIT uniformity\n    pit = dist.cdf(data)\n    pit_ks, pit_pval = stats.kstest(pit, 'uniform')\n    results['pit_pval'] = pit_pval\n    results['pit_pass'] = pit_pval > alpha\n    \n    # 4. Overall verdict\n    results['all_pass'] = results['ks_pass'] and results['pit_pass']\n    \n    return results\n\n\n# Test on good fit\ndata_good = np.random.lognormal(2, 0.5, 500)\ndist_good = get_distribution('lognormal')\ndist_good.fit(data_good)\n\nval_good = validate_fit(data_good, dist_good)\n\nprint(\"Validation: Lognormal data ‚Üí Lognormal fit\\n\")\nprint(f\"  AIC:            {val_good['aic']:.2f}\")\nprint(f\"  BIC:            {val_good['bic']:.2f}\")\nprint(f\"  KS test:        {'PASS' if val_good['ks_pass'] else 'FAIL'} (p={val_good['ks_pval']:.3f})\")\nprint(f\"  PIT test:       {'PASS' if val_good['pit_pass'] else 'FAIL'} (p={val_good['pit_pval']:.3f})\")\nprint(f\"  Overall:        {'‚úì GOOD FIT' if val_good['all_pass'] else '‚úó POOR FIT'}\\n\")\n\n\n# Test on poor fit\ndata_bimodal = np.concatenate([\n    np.random.normal(10, 2, 250),\n    np.random.normal(30, 3, 250)\n])\ndist_poor = get_distribution('normal')\ndist_poor.fit(data_bimodal)\n\nval_poor = validate_fit(data_bimodal, dist_poor)\n\nprint(\"Validation: Bimodal data ‚Üí Normal fit (should fail)\\n\")\nprint(f\"  AIC:            {val_poor['aic']:.2f}\")\nprint(f\"  BIC:            {val_poor['bic']:.2f}\")\nprint(f\"  KS test:        {'PASS' if val_poor['ks_pass'] else 'FAIL'} (p={val_poor['ks_pval']:.3f})\")\nprint(f\"  PIT test:       {'PASS' if val_poor['pit_pass'] else 'FAIL'} (p={val_poor['pit_pval']:.3f})\")\nprint(f\"  Overall:        {'‚úì GOOD FIT' if val_poor['all_pass'] else '‚úó POOR FIT (as expected)'}\\n\")\n\n\n# ============================================================================\n# KEY TAKEAWAYS\n# ============================================================================\n\nprint(\"\\n" + \"‚ïê" * 70)\nprint(\"üéì KEY TAKEAWAYS\")\nprint(\"‚ïê" * 70)\nprint(\"\"\"\n1. MULTIPLE VALIDATION METHODS:\n   - AIC/BIC: Relative comparison (lower better)\n   - KS test: Formal hypothesis test (p > 0.05 = good)\n   - Chi-square: For binned/discrete data\n   - Q-Q plot: Visual assessment of quantiles\n   - PIT: Probability integral transform uniformity\n\n2. INTERPRETING P-VALUES:\n   - p > 0.05: Cannot reject H‚ÇÄ (good fit)\n   - p < 0.05: Reject H‚ÇÄ (poor fit)\n   - But: Don't rely on single test!\n   - With large n, even tiny deviations significant\n\n3. RECOMMENDED WORKFLOW:\n   a) Use AIC/BIC to select best candidate\n   b) Validate winner with KS or chi-square test\n   c) Visual check with Q-Q plot or histogram\n   d) If critical application: bootstrap confidence intervals\n\n4. WHEN FIT IS POOR:\n   - Try different distribution family\n   - Consider mixture models\n   - Check for outliers/contamination\n   - Transform data (log, sqrt, Box-Cox)\n   - Accept that some data just doesn't fit standard distributions\n\n5. NEXT STEPS:\n   - See examples/02_advanced/03_bootstrap.py for uncertainty\n   - See examples/03_plotting/ for diagnostic plots\n   - See 06_verbose_mode.py for educational explanations\n\"\"\")\